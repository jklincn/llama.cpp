#include "ggml-moe.h"

// C++ standard library headers
#include <cmath>
#include <cstdio>
#include <cstdlib>  // For system()
#include <cstring>
#include <exception>
#include <fstream>
#include <iomanip>
#include <sstream>
#include <string>
#include <vector>

// ggml internal headers
#include "ggml-backend.h"
#include "ggml-impl.h"

/**
 * @struct MoeTopkCollector
 * C++ implementation of the MoE TopK tensor data collector.
 * This definition is hidden from C code.
 */
struct MoeTopkCollector {
    std::vector<uint8_t> buffer;  // Temporary data buffer
    std::string          output_dir = "moe_topk_data";
    std::ofstream        metadata_file;
    int                  tensor_counter = 0;
    bool                 initialized    = false;

    // Statistics
    int    total_collected   = 0;
    size_t total_bytes_saved = 0;

    // Destructor to ensure metadata_file is closed
    ~MoeTopkCollector() {
        if (metadata_file.is_open()) {
            metadata_file.close();
        }
    }
};

// C-compatible API implementations

MoeTopkCollector * create_moe_topk_collector(void) {
    return new (std::nothrow) MoeTopkCollector();
}

void destroy_moe_topk_collector(MoeTopkCollector * collector) {
    if (!collector) {
        return;
    }
    // Print final summary before destroying
    print_collection_summary(collector);
    delete collector;
}

// --- Helper function prototypes (internal to this file) ---

static bool        is_target_tensor(const char * tensor_name);
static std::string ggml_ne_string(const ggml_tensor * t);
static bool        save_tensor_npy(const std::string & filepath, ggml_tensor * t, uint8_t * data);
static void        save_metadata(MoeTopkCollector * collector, ggml_tensor * t, const std::string & filename);

// --- Function Implementations ---

/**
 * æ£€æŸ¥å¼ é‡åç§°æ˜¯å¦åŒ¹é…ç›®æ ‡å‰ç¼€
 */
static bool is_target_tensor(const char * tensor_name) {
    if (!tensor_name) {
        return false;
    }
    return strncmp(tensor_name, "ffn_moe_topk", 12) == 0;
}

/**
 * è·å–å¼ é‡ç»´åº¦å­—ç¬¦ä¸²ï¼ˆå®ç°ç‰ˆæœ¬ï¼‰
 */
static std::string ggml_ne_string(const ggml_tensor * t) {
    std::string str;
    for (int i = 0; i < GGML_MAX_DIMS; ++i) {
        // åªæ·»åŠ å­˜åœ¨çš„ç»´åº¦
        if (t->ne[i] > 0) {
            if (!str.empty()) {
                str += ", ";
            }
            str += std::to_string(t->ne[i]);
        }
    }
    return str;
}

/**
 * ä¿å­˜å¼ é‡ä¸ºNPYæ ¼å¼æ–‡ä»¶
 */
static bool save_tensor_npy(const std::string & filepath, ggml_tensor * t, uint8_t * data) {
    std::ofstream file(filepath, std::ios::binary);
    if (!file) {
        GGML_LOG_ERROR("æ— æ³•åˆ›å»ºæ–‡ä»¶: %s\n", filepath.c_str());
        return false;
    }

    try {
        // NPYæ–‡ä»¶å¤´ï¼šé­”æ•° + ç‰ˆæœ¬
        file.write("\x93NUMPY", 6);
        file.write("\x01\x00", 2);  // ç‰ˆæœ¬ 1.0

        // æ„é€ æ•°æ®ç±»å‹å­—ç¬¦ä¸²
        std::string dtype;
        switch (t->type) {
            case GGML_TYPE_F32:
                dtype = "'<f4'";
                break;
            case GGML_TYPE_F16:
                dtype = "'<f2'";
                break;
            case GGML_TYPE_I64:
                dtype = "'<i8'";
                break;
            case GGML_TYPE_I32:
                dtype = "'<i4'";
                break;
            case GGML_TYPE_I16:
                dtype = "'<i2'";
                break;
            case GGML_TYPE_I8:
                dtype = "'<i1'";
                break;
            default:
                GGML_LOG_ERROR("ä¸æ”¯æŒçš„æ•°æ®ç±»å‹: %s\n", ggml_type_name(t->type));
                return false;
        }

        // æ„é€ shapeå­—ç¬¦ä¸²
        std::ostringstream shape_stream;
        shape_stream << "(";
        bool first = true;
        for (int i = 0; i < GGML_MAX_DIMS; ++i) {
            if (t->ne[i] > 1 || (i == 0 && first)) {
                if (!first) {
                    shape_stream << ", ";
                }
                shape_stream << t->ne[i];
                first = false;
            }
        }
        if (!first) {
            shape_stream << ",";  // Python tupleéœ€è¦é€—å·
        }
        shape_stream << ")";

        // æ„é€ å®Œæ•´çš„å¤´éƒ¨
        std::ostringstream header_stream;
        header_stream << "{'descr': " << dtype << ", 'fortran_order': False" << ", 'shape': " << shape_stream.str()
                      << ", }";

        std::string header = header_stream.str();

        // è®¡ç®—å¡«å……ï¼Œä½¿å¤´éƒ¨æ€»é•¿åº¦å¯¹é½åˆ°16å­—èŠ‚
        size_t total_header_size = 8 + 2 + header.size() + 1;  // é­”æ•°+ç‰ˆæœ¬+å¤´é•¿åº¦+å¤´å†…å®¹+æ¢è¡Œ
        size_t padding           = (16 - (total_header_size % 16)) % 16;
        header += std::string(padding, ' ') + "\n";

        // å†™å…¥å¤´éƒ¨é•¿åº¦
        uint16_t header_len = header.size();
        file.write(reinterpret_cast<const char *>(&header_len), 2);

        // å†™å…¥å¤´éƒ¨å†…å®¹
        file.write(header.c_str(), header.size());

        // å†™å…¥å¼ é‡æ•°æ®
        size_t data_size = ggml_nbytes(t);
        file.write(reinterpret_cast<const char *>(data), data_size);

        file.close();
        return file.good();

    } catch (const std::exception & e) {
        GGML_LOG_ERROR("ä¿å­˜NPYæ–‡ä»¶æ—¶å‡ºé”™: %s\n", e.what());
        return false;
    }
}

/**
 * ä¿å­˜å¼ é‡å…ƒæ•°æ®åˆ°CSVæ–‡ä»¶
 */
static void save_metadata(MoeTopkCollector * collector, ggml_tensor * t, const std::string & filename) {
    if (!collector->metadata_file.is_open()) {
        std::string meta_path = collector->output_dir + "/metadata.csv";
        collector->metadata_file.open(meta_path);
        if (!collector->metadata_file.is_open()) {
            GGML_LOG_ERROR("æ— æ³•åˆ›å»ºå…ƒæ•°æ®æ–‡ä»¶: %s\n", meta_path.c_str());
            return;
        }

        // å†™å…¥CSVå¤´éƒ¨
        collector->metadata_file << "åºå·,å¼ é‡åç§°,æ–‡ä»¶å,å½¢çŠ¶,æ•°æ®ç±»å‹,å…ƒç´ æ•°é‡,å­—èŠ‚å¤§å°,æ“ä½œç±»å‹\n";
    }

    // è®¡ç®—å…ƒç´ æ€»æ•°
    size_t total_elements = 1;
    for (int i = 0; i < GGML_MAX_DIMS; ++i) {
        if (t->ne[i] > 1 || i == 0) {
            total_elements *= t->ne[i];
        }
    }

    // å†™å…¥å½“å‰å¼ é‡çš„å…ƒæ•°æ®
    collector->metadata_file << collector->tensor_counter << "," << "\"" << (t->name[0] != '\0' ? t->name : "unnamed")
                             << "\","
                             << "\"" << filename << "\","
                             << "\"" << ggml_ne_string(t) << "\","
                             << "\"" << ggml_type_name(t->type) << "\"," << total_elements << "," << ggml_nbytes(t)
                             << ","
                             << "\"" << ggml_op_desc(t) << "\"\n";

    collector->metadata_file.flush();
}

/**
 * MoE TopKå¼ é‡é‡‡é›†å›è°ƒå‡½æ•°
 */
bool moe_topk_collector_callback(struct ggml_tensor * t, bool ask, void * user_data) {
    auto * collector = (MoeTopkCollector *) user_data;

    if (ask) {
        // åªå¯¹ç›®æ ‡å¼ é‡æ„Ÿå…´è¶£
        return is_target_tensor(t->name);
    }

    // å†æ¬¡ç¡®è®¤æ˜¯å¦ä¸ºç›®æ ‡å¼ é‡ï¼ˆåŒé‡æ£€æŸ¥ï¼‰
    if (!is_target_tensor(t->name)) {
        return true;
    }

    const struct ggml_tensor * src0 = t->src[0];
    const struct ggml_tensor * src1 = t->src[1];

    // è¾“å‡ºåŸºæœ¬ä¿¡æ¯
    char src1_str[128] = { 0 };
    if (src1) {
        snprintf(src1_str, sizeof(src1_str), "%s{%s}", src1->name, ggml_ne_string(src1).c_str());
    }

    GGML_LOG_INFO("ğŸ¯ [MoE TopK] %s: %s = (%s) %s(%s{%s}, %s}) = {%s}\n", __func__, t->name, ggml_type_name(t->type),
                  ggml_op_desc(t), src0->name, ggml_ne_string(src0).c_str(), src1 ? src1_str : "",
                  ggml_ne_string(t).c_str());

    // å¤„ç†æ•°æ®è·å–ï¼ˆGPU -> CPU å¦‚æœéœ€è¦ï¼‰
    const bool is_host  = ggml_backend_buffer_is_host(t->buffer);
    uint8_t *  data_ptr = nullptr;

    if (!is_host) {
        // ä»GPUå¤åˆ¶æ•°æ®åˆ°CPU
        size_t n_bytes = ggml_nbytes(t);
        collector->buffer.resize(n_bytes);
        ggml_backend_tensor_get(t, collector->buffer.data(), 0, n_bytes);
        data_ptr = collector->buffer.data();
        GGML_LOG_INFO("ğŸ“¥ ä»GPUå¤åˆ¶äº† %zu å­—èŠ‚æ•°æ®\n", n_bytes);
    } else {
        // æ•°æ®å·²ç»åœ¨CPUä¸Š
        data_ptr = (uint8_t *) t->data;
        GGML_LOG_INFO("ğŸ“‹ æ•°æ®å·²åœ¨CPUå†…å­˜ä¸­\n");
    }

    // åªå¤„ç†éé‡åŒ–å¼ é‡
    if (!ggml_is_quantized(t->type)) {
        // æ„é€ æ–‡ä»¶å
        std::ostringstream filename_stream;
        filename_stream << std::setfill('0') << std::setw(4) << collector->tensor_counter << "_"
                        << (t->name[0] != '\0' ? t->name : "unnamed") << ".npy";
        std::string filename = filename_stream.str();
        std::string filepath = collector->output_dir + "/" + filename;

        // ä¿å­˜NPYæ–‡ä»¶
        if (save_tensor_npy(filepath, t, data_ptr)) {
            size_t file_size = ggml_nbytes(t);
            collector->total_bytes_saved += file_size;
            collector->total_collected++;

            GGML_LOG_INFO("ğŸ’¾ å·²ä¿å­˜: %s (%.2f KB)\n", filename.c_str(), file_size / 1024.0);

            // ä¿å­˜å…ƒæ•°æ®
            save_metadata(collector, t, filename);

            // æ˜¾ç¤ºä¸€äº›åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
            size_t total_elements = 1;
            for (int i = 0; i < GGML_MAX_DIMS; ++i) {
                if (t->ne[i] > 1 || i == 0) {
                    total_elements *= t->ne[i];
                }
            }

            GGML_LOG_INFO("ğŸ“Š å¼ é‡ç»Ÿè®¡: %zuä¸ªå…ƒç´ , å½¢çŠ¶=%s, ç±»å‹=%s\n", total_elements, ggml_ne_string(t).c_str(),
                          ggml_type_name(t->type));

        } else {
            GGML_LOG_ERROR("âŒ ä¿å­˜å¤±è´¥: %s\n", filepath.c_str());
        }

        collector->tensor_counter++;
    } else {
        GGML_LOG_INFO("âš ï¸  è·³è¿‡é‡åŒ–å¼ é‡: %s (ç±»å‹: %s)\n", t->name, ggml_type_name(t->type));
    }

    return true;
}

/**
 * åˆå§‹åŒ–MoE TopKæ•°æ®æ”¶é›†å™¨
 */
bool init_moe_topk_collector(MoeTopkCollector * collector, const char * output_dir_c_str) {
    if (!collector) {
        return false;
    }

    collector->output_dir        = output_dir_c_str;
    collector->tensor_counter    = 0;
    collector->total_collected   = 0;
    collector->total_bytes_saved = 0;
    collector->buffer.clear();
    if (collector->metadata_file.is_open()) {
        collector->metadata_file.close();
    }

    // åˆ›å»ºè¾“å‡ºç›®å½•
    std::string mkdir_cmd = "mkdir -p " + collector->output_dir;
    if (system(mkdir_cmd.c_str()) != 0) {
        GGML_LOG_ERROR("æ— æ³•åˆ›å»ºè¾“å‡ºç›®å½•: %s\n", collector->output_dir.c_str());
        return false;
    }

    collector->initialized = true;
    GGML_LOG_INFO("ğŸš€ MoE TopKæ•°æ®æ”¶é›†å™¨å·²åˆå§‹åŒ–\n");
    GGML_LOG_INFO("ğŸ“ è¾“å‡ºç›®å½•: %s\n", collector->output_dir.c_str());
    GGML_LOG_INFO("ğŸ¯ ç›®æ ‡å¼ é‡: ffn_moe_topk*\n");

    return true;
}

/**
 * æ‰“å°æ”¶é›†ç»Ÿè®¡ä¿¡æ¯
 */
void print_collection_summary(const MoeTopkCollector * collector) {
    if (!collector) {
        return;
    }
    GGML_LOG_INFO("\n=== MoE TopK æ•°æ®æ”¶é›†æŠ¥å‘Š ===\n");
    GGML_LOG_INFO("æ”¶é›†çš„å¼ é‡æ•°é‡: %d\n", collector->total_collected);
    GGML_LOG_INFO("æ€»æ•°æ®å¤§å°: %.2f MB\n", collector->total_bytes_saved / 1024.0 / 1024.0);
    GGML_LOG_INFO("å¹³å‡å¼ é‡å¤§å°: %.2f KB\n", collector->total_collected > 0 ?
                                                 (collector->total_bytes_saved / 1024.0 / collector->total_collected) :
                                                 0);
    GGML_LOG_INFO("æ•°æ®ä¿å­˜è·¯å¾„: %s/\n", collector->output_dir.c_str());
    GGML_LOG_INFO("å…ƒæ•°æ®æ–‡ä»¶: %s/metadata.csv\n", collector->output_dir.c_str());

    if (collector->total_collected > 0) {
        GGML_LOG_INFO("\nğŸ’¡ ä½¿ç”¨Pythonåˆ†ææ•°æ®:\n");
        GGML_LOG_INFO("   import numpy as np\n");
        GGML_LOG_INFO("   import pandas as pd\n");
        GGML_LOG_INFO("   \n");
        GGML_LOG_INFO("   # åŠ è½½å…ƒæ•°æ®\n");
        GGML_LOG_INFO("   metadata = pd.read_csv('%s/metadata.csv')\n", collector->output_dir.c_str());
        GGML_LOG_INFO("   print(metadata)\n");
        GGML_LOG_INFO("   \n");
        GGML_LOG_INFO("   # åŠ è½½ç¬¬ä¸€ä¸ªå¼ é‡\n");
        GGML_LOG_INFO("   first_tensor = np.load('%s/' + metadata.iloc[0]['æ–‡ä»¶å'])\n", collector->output_dir.c_str());
        GGML_LOG_INFO("   print(f'Shape: {first_tensor.shape}, Data: {first_tensor}')\n");
    }

    GGML_LOG_INFO("============================\n\n");
}
